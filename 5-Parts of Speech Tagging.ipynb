{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4cfff6-a588-493b-822a-c54a0b68136b",
   "metadata": {},
   "source": [
    "# Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46670741-729d-4e6b-a10b-3350f450c136",
   "metadata": {},
   "source": [
    "### One of the more powerful aspects of the NLTK module is the Part of Speech tagging that it can do for you. This means labeling words in a sentence as nouns, adjectives, verbs...etc. Even more impressive, it also labels by tense, and more. Here's a list of the tags, what they mean, and some examples:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "029e845a-7d3b-4e12-9566-2d81cacdbb4c",
   "metadata": {},
   "source": [
    "POS tag list:\n",
    "\n",
    "CC\tcoordinating conjunction\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "FW\tforeign word\n",
    "IN\tpreposition/subordinating conjunction\n",
    "JJ\tadjective\t'big'\n",
    "JJR\tadjective, comparative\t'bigger'\n",
    "JJS\tadjective, superlative\t'biggest'\n",
    "LS\tlist marker\t1)\n",
    "MD\tmodal\tcould, will\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "PDT\tpredeterminer\t'all the kids'\n",
    "POS\tpossessive ending\tparent\\'s\n",
    "PRP\tpersonal pronoun\tI, he, she\n",
    "PRP$\tpossessive pronoun\tmy, his, hers\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "RP\tparticle\tgive up\n",
    "TO\tto\tgo 'to' the store.\n",
    "UH\tinterjection\terrrrrrrrm\n",
    "VB\tverb, base form\ttake\n",
    "VBD\tverb, past tense\ttook\n",
    "VBG\tverb, gerund/present participle\ttaking\n",
    "VBN\tverb, past participle\ttaken\n",
    "VBP\tverb, sing. present, non-3d\ttake\n",
    "VBZ\tverb, 3rd person sing. present\ttakes\n",
    "WDT\twh-determiner\twhich\n",
    "WP\twh-pronoun\twho, what\n",
    "WP$\tpossessive wh-pronoun\twhose\n",
    "WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bedc871e-a093-4b72-b728-8653752b6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Speech of Mahatma Gandhi\n",
    "para = \"\"\"In all probability this will be my last speech to you. Even if the Government allow me to march tomorrow morning, this will\n",
    "be my last speech on the sacred banks of the Sabarmati. Possibly these may be the last words of my life here.I have already told you\n",
    "yesterday what I had to say. Today I shall confine myself to what you should do after my companions and I are arrested. The programme\n",
    "of the march to Jalalpur must be fulfilled as originally settled. The enlistment of the volunteers for this purpose should be confined\n",
    "to Gujarat only. From what I have been and heard during the last fortnight, I am inclined to believe that the stream of civil resisters\n",
    "will flow unbroken.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "437c06ad-2dd3-4fd9-b7af-f169a402f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\faiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a78816fc-077f-432e-b794-f1dbb8c4f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b490fd80-bd34-44ba-a834-7083b287c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41cc5a70-2a90-479e-9b2f-d4b61355ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In all probability this will be my last speech to you.',\n",
       " 'Even if the Government allow me to march tomorrow morning, this will\\nbe my last speech on the sacred banks of the Sabarmati.',\n",
       " 'Possibly these may be the last words of my life here.I have already told you\\nyesterday what I had to say.',\n",
       " 'Today I shall confine myself to what you should do after my companions and I are arrested.',\n",
       " 'The programme\\nof the march to Jalalpur must be fulfilled as originally settled.',\n",
       " 'The enlistment of the volunteers for this purpose should be confined\\nto Gujarat only.',\n",
       " 'From what I have been and heard during the last fortnight, I am inclined to believe that the stream of civil resisters\\nwill flow unbroken.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc97861-b1d4-49da-8876-f41d06a58ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'IN'), ('probability', 'NN'), ('last', 'JJ'), ('speech', 'NN'), ('.', '.')]\n",
      "[('Even', 'RB'), ('Government', 'NNP'), ('allow', 'IN'), ('march', 'NN'), ('tomorrow', 'NN'), ('morning', 'NN'), (',', ','), ('last', 'JJ'), ('speech', 'NN'), ('sacred', 'VBD'), ('banks', 'NNS'), ('Sabarmati', 'NNP'), ('.', '.')]\n",
      "[('Possibly', 'RB'), ('may', 'MD'), ('last', 'JJ'), ('words', 'NNS'), ('life', 'NN'), ('here.I', 'NN'), ('already', 'RB'), ('told', 'VBD'), ('yesterday', 'NN'), ('I', 'PRP'), ('say', 'VBP'), ('.', '.')]\n",
      "[('Today', 'NN'), ('I', 'PRP'), ('shall', 'MD'), ('confine', 'VB'), ('companions', 'NNS'), ('I', 'PRP'), ('arrested', 'VBD'), ('.', '.')]\n",
      "[('The', 'DT'), ('programme', 'NN'), ('march', 'NN'), ('Jalalpur', 'NNP'), ('must', 'MD'), ('fulfilled', 'VB'), ('originally', 'RB'), ('settled', 'VBN'), ('.', '.')]\n",
      "[('The', 'DT'), ('enlistment', 'NN'), ('volunteers', 'NNS'), ('purpose', 'VBP'), ('confined', 'VBN'), ('Gujarat', 'NNP'), ('.', '.')]\n",
      "[('From', 'IN'), ('I', 'PRP'), ('heard', 'VBD'), ('last', 'JJ'), ('fortnight', 'NN'), (',', ','), ('I', 'PRP'), ('inclined', 'VBD'), ('believe', 'VBP'), ('stream', 'NN'), ('civil', 'JJ'), ('resisters', 'NNS'), ('flow', 'VBP'), ('unbroken', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#We will find the Pos Tags\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words('english'))]\n",
    "    tags=nltk.pos_tag(words)\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e26912d0-9d01-415d-878a-d7e3a2d92ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Charminar', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('Monument', 'NN'), ('in', 'IN'), ('Hyderabad', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag(\"Charminar is a beautiful Monument in Hyderabad\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52433f9c-6ca3-49a0-af13-bb2020b0da87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
