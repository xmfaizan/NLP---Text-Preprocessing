{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af92226-1261-40c1-b0a1-6e1e98396f0a",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ed0e7-5c17-4835-8017-d1c2d3b13205",
   "metadata": {},
   "source": [
    "### Tokenization is a common step used to help prepare language data for further use. The process itself involves breaking a larger text body into smaller units, often down to just sentences, groups of words (often referred to as n-grams), single words, or even just groups of characters or subwords. These tokens can then be further processed and fed into different NLP processes. Essentially, tokenization creates the core vocabulary that further analysis is built on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e491419-b4f7-4be9-9c78-78f2abacd7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     --------- ------------------------------ 10.2/42.0 kB ? eta -:--:--\n",
      "     -------------------------------------- 42.0/42.0 kB 511.8 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\faiza\\anaconda3\\envs\\nlpbasics\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.5 MB 871.5 kB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.1/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.2/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.3/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.4/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.5/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 0.8/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 0.9/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.3/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.5.15-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.5 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 61.4/268.5 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 174.1/268.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 268.5/268.5 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 92.2/97.9 kB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 97.9/97.9 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/301.8 kB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 174.1/301.8 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 235.5/301.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.8/301.8 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 41.0/78.3 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.3/78.3 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30fa8789-5ba8-4890-b972-f529263d9830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\faiza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f7622b-bc33-4915-bf8c-6a49cc54e9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus =\"\"\"Hello Welcome, to my NLP Basics.\n",
    "PLease stay tuned for more notebooks! To know more about NLP\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3935e066-78c1-4f40-a095-e0694720eb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome, to my NLP Basics.\n",
      "PLease stay tuned for more notebooks! To know more about NLP\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7beb95c-dee9-4499-8a1e-b39033b4fd60",
   "metadata": {},
   "source": [
    "Paragraph(Corpus) ---> Sentences(Documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ade1ce2c-5e67-49d4-aaaa-4e554843a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade81c72-20ee-4268-91af-6fc86aae21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f63838d-66d1-437f-b41a-8944cb4f7a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb6b68f-58b0-44da-b6b8-302bc6a739af",
   "metadata": {},
   "source": [
    "Paragraphs/Sentences ---> Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1071989-dea7-4c4a-8cff-6eb88eccff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b69d5b1f-092a-4645-8c6d-1ba3cfe54e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb84a937-a184-4c86-902f-6c504461cf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'my',\n",
       " 'NLP',\n",
       " 'Basics',\n",
       " '.',\n",
       " 'PLease',\n",
       " 'stay',\n",
       " 'tuned',\n",
       " 'for',\n",
       " 'more',\n",
       " 'notebooks',\n",
       " '!',\n",
       " 'To',\n",
       " 'know',\n",
       " 'more',\n",
       " 'about',\n",
       " 'NLP']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630aca1b-42f1-4a35-bd39-a344d37c0ee7",
   "metadata": {},
   "source": [
    "To separate out the Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "063fc4e0-fc62-4390-a1e1-76ec0dcb7a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "885b6cb9-2c56-442b-a2ed-25b8668b128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'my',\n",
       " 'NLP',\n",
       " 'Basics',\n",
       " '.',\n",
       " 'PLease',\n",
       " 'stay',\n",
       " 'tuned',\n",
       " 'for',\n",
       " 'more',\n",
       " 'notebooks',\n",
       " '!',\n",
       " 'To',\n",
       " 'know',\n",
       " 'more',\n",
       " 'about',\n",
       " 'NLP']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce5e064-59a6-4054-9f9c-cbe71b056473",
   "metadata": {},
   "source": [
    "full stop not treated as a separate word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e16ed519-8ccb-4f1d-8e50-b9d2b8327f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "661969dd-e60f-4e32-80d2-a29a99bbd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea66bec-a153-484a-8784-3bad5bbe527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'my',\n",
       " 'NLP',\n",
       " 'Basics.',\n",
       " 'PLease',\n",
       " 'stay',\n",
       " 'tuned',\n",
       " 'for',\n",
       " 'more',\n",
       " 'notebooks',\n",
       " '!',\n",
       " 'To',\n",
       " 'know',\n",
       " 'more',\n",
       " 'about',\n",
       " 'NLP']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b219721-f653-47a7-acec-c171ad36219d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
